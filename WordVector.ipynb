{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.nn import embedding_lookup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cn = '../Resource/archive_/chinese.zh'\n",
    "path_en = '../Resource/archive_/english.en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        data = pd.Series(f.readlines())\n",
    "        data = data.str.replace('\\n', ' ')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cn = load_data(path_cn)\n",
    "df_en = load_data(path_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.691 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "df_cn = df_cn.apply(lambda x: ' '.join(jieba.cut(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cn_train = df_cn[: int(len(df_cn) * 0.7)]\n",
    "df_en_train = df_en[: int(len(df_cn) * 0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Use the Tokenizer to transform the word into number \n",
    "    num_words is None means that all words will be contain\n",
    "    Example:\n",
    "    If have a sentence is \"I love my dog\"\n",
    "    After \"fit_on_texts\" is {'I': 1, 'love': 2, 'my': 3, 'dog': 4}\n",
    "    From the mentioned example:\n",
    "    After \"texts_to_sequences\", the sentence becames [1, 2, 3, 4]\n",
    "    \"pad_sequences\" is used to let all sentences as the same list size.\n",
    "'''\n",
    " max_len = 140\n",
    "def to_vector(data):\n",
    "    tokenizer = Tokenizer(num_words=None, char_level=False)\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    seq = tokenizer.texts_to_sequences(data)\n",
    "    vector = pad_sequences(seq, padding='post', maxlen=max_len)\n",
    "    return vector, len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_vector, total_cn = to_vector(df_cn_train)\n",
    "en_vector, total_en = to_vector(df_en_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176943, 140)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cn_vector)\n",
    "en_vector[0].size\n",
    "en_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length_cn = cn_vector[0].size \n",
    "max_sequence_length_en = en_vector[0].size\n",
    "learning_rate = 0.01\n",
    "def initial_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Embedding(total_cn+1, max_sequence_length_en, input_length=max_sequence_length_cn),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True)),\n",
    "        keras.layers.Dense(total_en+1 ,activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initial_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 140, 140)          10868760  \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 140, 64)           44288     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 140, 58632)        3811080   \n",
      "=================================================================\n",
      "Total params: 14,724,128\n",
      "Trainable params: 14,724,128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5422/7078 [=====================>........] - ETA: 6:31 - loss: 1.1793 - accuracy: 0.8480"
     ]
    }
   ],
   "source": [
    "model.fit(cn_vector, en_vector, batch_size=25, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
