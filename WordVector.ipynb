{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.nn import embedding_lookup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cn = '../Resource/archive_/chinese.zh'\n",
    "path_en = '../Resource/archive_/english.en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path) as f:\n",
    "        data = pd.Series(f.readlines())\n",
    "        data = data.str.replace('\\n', ' ')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cn = load_data(path_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/sz/wlf98q891gg7q8ys9cy9z99m0000gn/T/jieba.cache\n",
      "Loading model cost 0.367 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "df_cn = df_cn.apply(lambda x: ' '.join(jieba.cut(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Use the Tokenizer to transform the word into number \n",
    "    num_words is None means that all words will be contain\n",
    "    Example:\n",
    "    If have a sentence is \"I love my dog\"\n",
    "    After \"fit_on_texts\" is {'I': 1, 'love': 2, 'my': 3, 'dog': 4}\n",
    "    From the mentioned example:\n",
    "    After \"texts_to_sequences\", the sentence becames [1, 2, 3, 4]\n",
    "    \"pad_sequences\" is used to let all sentences as the same list size.\n",
    "'''\n",
    "def to_vector(data):\n",
    "    tokenizer = Tokenizer(num_words=None, char_level=False)\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    seq = tokenizer.texts_to_sequences(data)\n",
    "    vector = pad_sequences(seq, padding='post')\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = to_vector(df_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5801,   24,  257, ...,    0,    0,    0],\n",
       "       [ 936,  313, 1490, ...,    0,    0,    0],\n",
       "       [ 168,  125,    2, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 202,  832, 6010, ...,    0,    0,    0],\n",
       "       [  77,  582,   50, ...,    0,    0,    0],\n",
       "       [  86,    2,   93, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
